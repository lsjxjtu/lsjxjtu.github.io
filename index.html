<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Sijia Liu - CSE@MSU </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Sijia</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="links\CV_Sijia_Liu_2023_2Pages.pdf">CV(2&nbsp;pages)</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="funding.html">Projects</a></div>
<div class="menu-item"><a href="https://www.optml-group.com">OPTML&nbsp;Group</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="CSE891.html">CSE891</a></div>
<div class="menu-category">Others</div>
<div class="menu-item"><a href="talk.html">Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Sijia Liu - CSE@MSU </h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/sijia.png" alt="Temp" width="130px" />&nbsp;</td>
<td align="left"><p>Assistant Professor, <a href="https://www.cse.msu.edu/">Department of Computer Science and Engineering</a>,<br />
<a href="https://msu.edu/">Michigan State University</a>, East Lansing, MI 48824<br />
Affiliated Professor, <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>, Cambridge, MA 02142<br />
Email: liusiji5@msu.edu <br />
Twitter: @sijialiu17 <br />
<a href="https://scholar.google.com/citations?user=C7dO_UgAAAAJ&amp;hl=en">Google scholar</a> <br /></p>
</td></tr></table>
<div class="infoblock">
<div class="blocktitle">Prospective Students</div>
<div class="blockcontent">
<p>I always look for working with highly motivated students, in terms of RA/TA/externship/internship/visiting students.
Interested candidates are strongly encouraged to contact me by <a href="mailto:liusiji5@msu.edu">email</a>, together with resume and transcripts.</p>
</div></div>
<h2>Short Bio</h2>
<p>Sijia Liu received the Ph.D. degree (with All-University Doctoral Prize) in Electrical and Computer Engineering from Syracuse University, NY, USA, in 2016. 
He was a Postdoctoral Research Fellow at the University of Michigan, Ann Arbor, in 2016-2017, and a Research Staff Member at the MIT-IBM Watson AI Lab in 2018-2020. 
His research interests include scalable and trustworthy AI, e.g., adversarial deep learning, optimization theory and methods, computer vision, and computational biology. 
He received the Best Student Paper Award at the 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP’16), and the Best Paper Runner-Up Award at the 38th Conference on Uncertainty in Artificial Intelligence (UAI’22). 
He has published over 50 papers at top-tier ML/CV conferences, such as NeurIPS, ICML, ICLR, CVPR, ICCV, ECCV, AISTATS, and AAAI (please refer to the <a href="https://csrankings.org">CS ranking</a>). </p>
<p>He is currently a Senior Member of IEEE, a Technical Committee (TC) Member of Machine Learning for Signal Processing (MLSP) in the IEEE’s Signal Processing Society, and an affiliated faculty at the MIT-IBM Watson AI Lab, IBM Research. He has organized a series of Adversarial ML workshops in <a href="https://advml-frontier.github.io/">ICML&rsquo;22</a> and <a href="https://sites.google.com/view/advml">KDD&rsquo;19-&rsquo;22</a>, and provided tutorials on Trustworthy and Scalable ML  in <a href="https://sites.google.com/view/aaai2023tutorial/home">AAAI&rsquo;23</a>, <a href="https://sites.google.com/view/neurips2022-frfm-turotial/home">NeurIPS&rsquo;22</a>, and <a href="https://sites.google.com/umich.edu/cvpr-2020-zoo">CVPR&rsquo;20</a>. </p>
<h2>Research Interests</h2>
<p>My research spans the areas of machine learning (ML)/deep learning (DL), optimization, computer vision, security, signal processing and data science, 
with a focus on developing learning algorithms and theory, and robust and explainable artificial intelligence (AI). 
These research themes provide a solid foundation for reaching my <b>long-term research objective: Making AI systems safe and scalable</b>. 
As AI moves from the lab into the real world (e.g., autonomous vehicles), ensuring its safety becomes a paramount requirement prior to 
its deployment. Moreover, as datasets, ML/DL models, and learning tasks become increasingly complex, 
getting ML/DL to scale calls for new advances in learning algorithm design.
Thus, robustness and scalability  underscore my current and future research, and of course, these two goals are intertwined.  
More  broadly,  the  study  towards robust and scalable AI could make a significant impact on machine learning theories, 
and induce more promising applications in, e.g., automated ML, meta-learning, privacy and security, hardware design, and big data analysis. 
I intend to seek a new learning frontier when the current learning algorithms become infeasible, and formalize  foundations  of  secure  learning.</p>
<p>Please refer to <a href="https://lsjxjtu.github.io/funding.html">Projects</a> and our <a href="https://www.optml-group.com/posts">OPTML</a> group for some research highlights.</p>
<h2>Representative Publications</h2>
<ul>
<li><p><b>Trustworthy AI</b> : Robustness, fairness, and model explanation</p>
</li>
</ul>
<ol>
<li><p><a href="https://arxiv.org/abs/2211.11635">Understanding and Improving Visual Prompting: A Label-Mapping Perspective</a> <br />
A. Chen, Y. Yao, P.-Y. Chen, Y. Zhang, <b>S. Liu</b> <br />
CVPR&rsquo;23</p>
</li>
<li><p><a href="https://arxiv.org/pdf/2112.12376.pdf">Revisiting and advancing fast adversarial training through the lens of bi-level optimization</a> <br /> 
Y. Zhang*, G. Zhang*, P. Khanduri, M. Hong, S. Chang, <b>S. Liu</b> (* Equal contribution) <br /> 
ICML’22</p>
</li>
<li><p><a href="https://openreview.net/pdf?id=gpp7cf0xdfN">Reverse Engineering of Imperceptible Adversarial Image Perturbations</a> <br /> 
Y. Gong*, Y. Yao*, Y. Li, Y. Zhang, X. Liu, X. Lin, <b>S. Liu</b> <br /> 
ICLR’22</p>
</li>
<li><p><a href="https://openreview.net/pdf?id=W9G_ImpHlQd">How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective</a><br />
Y. Zhang, Y. Yao, J. Jia, J. Yi, M. Hong, S. Chang, <b>S. Liu</b><br />
ICLR’22</p>
</li>
<li><p>Model Sparsity Can Simplify Machine Unlearning <br /> 
J. Jia*, J. Liu*, P. Ram, Y. Yao, G. Liu, Y. Liu, P. Sharma, <b>S. Liu</b> <br />
NeurIPS&rsquo;23</p>
</li>
</ol>
<ul>
<li><p><b>Scalable AI</b> : Model compression, distributed learning,  black-box optimization, and automated ML <br /></p>
</li>
</ul>
<ol>
<li><p><a href="https://arxiv.org/pdf/2210.04092.pdf">Advancing Model Pruning via Bi-level Optimization</a> <br />
Y. Zhang*, Y. Yao*, P. Ram, P. Zhao, T. Chen, M. Hong, Y. Wang, <b>S. Liu</b> <br />
NeurIPS’22</p>
</li>
<li><p><a href="https://arxiv.org/pdf/2206.06257.pdf">Distributed Adversarial Training to Robustify Deep Neural Networks at Scale</a> <br />
G. Zhang*, S. Lu*, Y. Zhang, X. Chen, P.-Y. Chen, Q. Fan, L. Martie, L. Horesh, M. Hong, <b>S. Liu</b> <br />
UAI’22 (Best Paper Runner-Up Award)</p>
</li>
<li><p><a href="https://arxiv.org/pdf/1909.13806.pdf">Min-Max Optimization without Gradients: Convergence and Applications to Adversarial ML</a> <br />
<b>S. Liu</b>, S. Lu, X. Chen, Y. Feng, K. Xu, A. Al-Dujaili, M. Hong, U.-M. O'Reilly <br />
ICML’20</p>
</li>
<li><p><a href="https://arxiv.org/pdf/2006.06224.pdf">A Primer on Zeroth-Order Optimization in Signal Processing and Machine Learning</a> <br />
<b>S. Liu</b>, P.-Y. Chen, B. Kailkhura, G. Zhang, A. O. Hero, P. K. Varshney <br />
IEEE Signal Processing Magazine, 2020</p>
</li>
<li><p><a href="https://arxiv.org/pdf/1905.00424.pdf">An ADMM Based Framework for AutoML Pipeline Configuration</a> <br />
<b>S. Liu</b>*, P. Ram*, D. Vijaykeerthy, D. Bouneffouf, G. Bramble, H. Samulowitz, D. Wang, A. Conn, A. Gray <br /> 
AAAI’20</p>
</li>
</ol>
<h2>News</h2>
<p>* <b>[Preprints]:</b> <a href="https://arxiv.org/abs/2310.11868">&ldquo;To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images &hellip; For Now&rdquo;</a>, <a href="https://arxiv.org/abs/2310.12508">SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation</a>, <a href="https://browse.arxiv.org/abs/2310.02025">&ldquo;DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training&rdquo;</a>.</p>
<p>* NeurIPS 2023: 3 Papers Accepted – 1 Spotlight and 2 Posters. Congratulations to Jignhan, Jiancheng, and Yuguang for their spotlight acceptance with 'Model Sparsity Simplifies Machine Unlearning.&rsquo; And kudos to Yihua, Yimeng, Aochuan, Jinghan, and Jiancheng for their poster acceptance with 'Selectivity Boosts Transfer Learning Efficiency.&rsquo;</p>
<p>* Grateful to receive a grant from Army Research Office (ARO) as the PI.</p>
<p>* Our paper on <a href="https://arxiv.org/abs/2308.10110v1">Adversarial Training for MoE</a> has been chosen for an Oral Presentation at <a href="https://iccv2023.thecvf.com">ICCV&rsquo;23</a>.</p>
<p>* Grateful to receive a gift funding from Cisco Research as the PI.</p>
<p>* Call for participation in <a href="https://advml-frontier.github.io">2nd AdvML-Frontiers Workshop</a>@ICML&rsquo;23.</p>
<p>* One paper in <a href="https://iccv2023.thecvf.com">ICCV&rsquo;23</a> on Adversarial Robustness of Mixture-of-Experts.</p>
<p>* Grateful to receive a CPS Medium Grant Award from NSF as a co-PI.</p>
<p>* Slides of our CVPR&rsquo;23 tutorial on Reverse Engineering of Deceptions (RED) is now available at the tutorial page. <a href="https://sites.google.com/view/cvpr2023red">[link]</a></p>
<p>* Our paper &ldquo;<a href="https://arxiv.org/pdf/2210.06284.pdf">Visual Prompting for Adversarial Robustness</a>&rdquo; received the <a href="https://drive.google.com/file/d/1PHjGXkCUSRJ3pQc4_8BGl_Y5aaRB-Nuw/view">Top 3% Paper Recognition</a> at ICASSP 2023. Congrats to Aochuan, Peter (internship at OPTML in 2022), Yuguang, and Pin-Yu (IBM Research)!</p>
<p>* Grateful to be elected as Associate Editor of IEEE Transactions on Aerospace and Electronic Systems.</p>
<p>* <i>Two</i> papers in <a href="https://icml.cc/">ICML&rsquo;23</a> and CFP for <a href="https://advml-frontier.github.io/">2nd AdvML-Frontiers Workshop</a>.</p>
<p>* A new arXiv paper is released: Model Sparsification Can Simplify Machine Unlearning! <a href="https://arxiv.org/pdf/2304.04934.pdf">[Paper]</a> <a href="https://github.com/OPTML-Group/Unlearn-Sparse">[Code]</a></p>
<p>* Grateful to receive a grant from Lawrence Livermore National Laboratory.</p>
<p>* Call for Papers and AdvML Rising Star Award Applications in the workshop <a href="https://advml-frontier.github.io/">AdvML-Frontiers</a>, ICML&rsquo;23</p>
<p>* A new arXiv paper is released: Adversarial attacks can be parsed to reveal victim model information! <a href="https://arxiv.org/pdf/2303.07474.pdf">[Paper]</a></p>
<p>* The 2nd Workshop on <a href="https://advml-frontier.github.io/">New Frontiers in Adversarial Machine Learning</a> has been accepted by <b>ICML&rsquo;23</b>.</p>
<p>* Grateful to receive a grant from DSO National Laboratories.</p>
<p>* <i>Two</i> papers in <a href="https://cvpr2023.thecvf.com">CVPR&rsquo;23</a>.</p>
<p>* <i>Three</i> papers in <a href="https://2023.ieeeicassp.org">ICASSP&rsquo;23</a>.</p>
<p>* CVPR&rsquo;23 tutorial on <i>Reverse Engineering of Deception: Foundations and Applications</i> is accepted and will be given with Xiaoming Liu (MSU) and Xue Lin (Northeastern).</p>
<p>* AAAI&rsquo;23 tutorial on Bi-level Optimization in ML:  Foundations and Applications is now available at <a href="https://sites.google.com/view/aaai2023tutorial/home">link</a>.</p>
<p>* <i>Four</i> papers in <a href="https://iclr.cc/Conferences/2023/Dates">ICLR&rsquo;23</a>: <a href="https://openreview.net/pdf?id=MjsDeTcDEy">Issues and Fixes in IRM</a>, <a href="https://openreview.net/pdf?id=5tKXUZil3X">TextGrad: Differentiable Solution to NLP Attack Generation</a>, <a href="https://openreview.net/pdf?id=4UldFtZ_CVF">Provable Benefits of Sparse GNN</a>, <a href="https://openreview.net/pdf?id=jClGv3Qjhb">Sample Complexity Analysis of ViT</a>.</p>
<p>* <i>One</i> paper in <a href="https://www.aspdac.com/aspdac2023/">ASP-DAC&rsquo;23</a>.</p>
<p>* <i>One</i> paper in <a href="https://saner2023.must.edu.mo/">SANER 2023</a>: <a href="https://arxiv.org/abs/2211.11711">Towards Both Robust and Accurate Code Models</a>; Equally contributed by Jinghan Jia (MSU) and Shashank Srikant (MIT).</p>
<p>* Grateful to be selected as a presenter of the AAAI 2023 New Faculty Highlight Program.</p>
<p>* Tutorial on <a href="https://sites.google.com/view/neurips2022-frfm-turotial/">Foundational Robustness of Foundation Models</a> will be given in NeurIPS&rsquo;22.</p>
<p>* Tutorial on Bi-level Machine Learning will be given in <a href="https://aaai.org/Conferences/AAAI-23/aaai23tutorials/">AAAI&rsquo;23</a>.</p>
<p>* <i>Two</i> papers in <a href="https://nips.cc">NeurIPS&rsquo;22</a>.</p>
<p>* Grateful to receive a Robust Intelligence (RI) Core Small Grant Award from NSF as the PI.</p>
<p>* Grateful to receive the Best Paper Runner-Up Award at UAI’2022 in recognition of our work “<a href="https://arxiv.org/pdf/2206.06257.pdf">Distributed Adversarial Training to Robustify Deep Neural Networks at Scale</a>”.</p>
<p>* <i>One</i> paper in <a href="https://www.auai.org/uai2022/">UAI’22</a> (Oral presentation).</p>
<p>* <i>Five</i> papers in <a href="https://icml.cc/Conferences/2022/CallForPapers">ICML’22</a>: <a href="https://arxiv.org/pdf/2112.12376.pdf">Bi-level adversarial training</a>; <a href="https://arxiv.org/pdf/2206.04762.pdf">Winning lottery tickets from robust pretraining</a>; <a href="https://arxiv.org/pdf/2206.07839v1.pdf">Pruning helps certified robustness</a>; <a href="https://arxiv.org/pdf/2112.04468.pdf">Contrastive learning theory</a>; Generalization theory of GCN.</p>
<p>* <i>One</i> paper in <a href="https://2022.naacl.org">NAACL&rsquo;22</a>.</p>
<p>* <i>One</i> paper in <a href="https://ijcai-22.org/">IJCAI&rsquo;22</a>.</p>
<p>* CFP: 1st Workshop on New Frontiers in Adversarial Machine Learning at ICML&rsquo;22 (<a href="https://advml-frontier.github.io/">AdvML-Frontiers@ICML&rsquo;22</a>).</p>
<p>* Grateful to receive a gift funding from Cisco Research as the PI.</p>
<p>* Congratulations to Yihua Zhang for his first CVPR paper.</p>
<p>* <i>Two</i> papers in <a href="https://cvpr2022.thecvf.com">CVPR 2022</a>.</p>
<p>* Congratulations to Yimeng Zhang, Yuguang Yao, Jianghan Jia for their first ICLR papers.</p>
<p>* <i>Five</i> papers in <a href="https://iclr.cc/">ICLR 2022</a>: <a href="https://openreview.net/pdf?id=gpp7cf0xdfN">Reverse Engineering of Adversaries</a>, <a href="https://openreview.net/pdf?id=W9G_ImpHlQd">Black-Box Defense</a> (spotlight), <a href="https://openreview.net/pdf?id=VqzXzA9hjaX">Learning to Optimize</a>, <a href="https://openreview.net/pdf?id=qiMXBIf4NfB">Self-Training Theory</a>, <a href="https://openreview.net/pdf?id=oj2yn1Q4Ett">Distributed Learning</a>.</p>
<p>* Our work on <a href="https://arxiv.org/pdf/2112.12376.pdf"><i>interpreting and advancing adversarial training via bi-level optimization</i></a> is now available on arXiv; equally contributed by Yihua Zhang (MSU) and Guanhua Zhang (UCSB).</p>
<p>* Grateful to receive a DARPA IP2 AIE Grant as a Co-PI.</p>
<p>* <i>Five</i> papers in <a href="https://nips.cc">NeurIPS 2021</a>.</p>
<p>* Our MSU-NEU team (with PI <a href="https://www.cse.msu.edu/~liuxm/index2.html">Xiaoming Liu</a> and co-PI <a href="https://web.northeastern.edu/xuelin/?page_id=60">Xue Lin</a>) entered the Phase 2 of DARPA AIE RED.</p>
<p>* <i>One</i> paper in <a href="https://icml.cc">ICML 2021</a>.</p>
<p>* MIT news ‘<a href="https://news.mit.edu/2021/toward-deep-learning-models-that-can-reason-about-code-like-humans-0415">Toward deep-learning models that can reason about code more like humans</a>’ on our ICLR’21 work ‘Adversarial Programs’ [<a href="https://openreview.net/pdf?id=PH5PH9ZO_4">paper</a>, <a href="https://github.com/ALFA-group/adversarial-code-generation">code</a>].</p>
<p>* <i>Two</i> papers in <a href="http://cvpr2021.thecvf.com">CVPR 2021</a>.</p>
<p>* <i>Two</i> papers in <a href="https://aistats.org/aistats2021/index.html">AISTATS 2021</a>.</p>
<p>* <i>Four</i> papers in <a href="https://iclr.cc">ICLR 2021</a>.</p>
<p>* <i>Three</i> papers in <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</p>
<p>* Grateful to receive a <a href="https://beta.sam.gov/opp/f108cad02f824285af5ca85e1f7481f4/view">DARPA RED AIE Grant</a> as a Co-PI.</p>
<div id="footer">
<div id="footer-text">
Page generated 2023-10-20 07:06:20 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
